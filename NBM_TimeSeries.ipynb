{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david-levin11/Verification_Notebooks/blob/main/NBM_TimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iYyzL_9EAm7"
      },
      "source": [
        "# **Title--Please Make a Copy of this Notebook Prior To Editing!**\n",
        "<br/>\n",
        "Description--Write your description of what the notebook will do and any pitfalls or caveats here.\n",
        "\n",
        "- David Levin, Arctic Testbed & Proving Ground, Anchorage Alaska"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t56SexSlUELy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNRHFuNmC-2K"
      },
      "source": [
        "##**2 - Install and Import Packages**\n",
        "This will take about a minute to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJaogqYCNB-Q",
        "outputId": "a975ceaf-381b-415d-9b50-d9cfa2e67929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.34.143)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.143 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.34.143)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.143->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.143->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.143->boto3) (1.16.0)\n",
            "Requirement already satisfied: pygrib in /usr/local/lib/python3.10/dist-packages (2.1.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pygrib) (24.1)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.10/dist-packages (from pygrib) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pygrib) (1.25.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj->pygrib) (2024.6.2)\n",
            "Requirement already satisfied: swifter in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (2.0.3)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.10/dist-packages (from swifter) (5.9.5)\n",
            "Requirement already satisfied: dask[dataframe]>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (2023.8.1)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from swifter) (4.66.4)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (24.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]>=2.10.0->swifter) (8.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->swifter) (1.25.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]>=2.10.0->swifter) (3.19.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.16.0)\n",
            "Process Pool Size: 20\n",
            "File /nas/atpg/data/nbm_verification/timeseries/obs_csv/obs.wind..2024-07-04 00:00:00.2024-07-07 00:00:00.csv already exists.\n",
            "['F001', 'F002', 'F003', 'F004', 'F005', 'F006', 'F007', 'F008', 'F009', 'F010', 'F011', 'F012', 'F013', 'F014', 'F015', 'F016', 'F017', 'F018', 'F019', 'F020', 'F021', 'F022', 'F023', 'F024', 'F025', 'F026', 'F027', 'F028', 'F029', 'F030', 'F031', 'F032', 'F033', 'F034', 'F035', 'F036', 'F037', 'F038', 'F039', 'F040', 'F041', 'F042', 'F043', 'F044', 'F045', 'F046', 'F047', 'F048', 'F049', 'F050', 'F051', 'F052', 'F053', 'F054', 'F055', 'F056', 'F057', 'F058', 'F059', 'F060', 'F061', 'F062', 'F063', 'F064', 'F065', 'F066', 'F067', 'F068', 'F069', 'F070', 'F071', 'F072']\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3\n",
        "!pip install pygrib\n",
        "!pip install swifter\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import requests\n",
        "import boto3\n",
        "import pygrib\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from functools import partial\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from multiprocessing import set_start_method, get_context\n",
        "######################### General Config #########################\n",
        "\n",
        "# @markdown <FONT SIZE=5>**1. Please Provide Your Synoptic API Token...**\n",
        "user_token = \"c6c8a66a96094960aabf1fed7d07ccf0\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown <FONT SIZE=5>**2. Select NBM Run**\n",
        "# @markdown <br><FONT SIZE=3>NBM 4.1 and 4.2 available as a threaded dataset\n",
        "# @markdown for PMaxT, PMinT, PQPF from 1/18/2023 to present\n",
        "start_date = \"2024-07-04\" # @param {type:\"date\"}\n",
        "# @markdown <FONT SIZE=5>**2. Select Run Start Time (UTC hour)**\n",
        "utctime =12 #@param {type:\"slider\", min:0, max:23, step:1}\n",
        "# @markdown <FONT SIZE=5>**2. Select Number Of Forecast Hours (0-240)**\n",
        "run_hours = 72 #@param {type:\"slider\", min:0, max:240, step:1}\n",
        "end_date = (datetime.strptime(start_date, '%Y-%m-%d') + timedelta(hours=run_hours)).strftime('%Y-%m-%d')\n",
        "# @markdown <FONT SIZE=5>**3. For Which Element?**\n",
        "element = \"wind\" # @param [\"maxt\", \"mint\", \"qpf24\", \"qpf12\", \"qpf06\", \"wind\", \"windgust\", \"rh\", \"td\"]\n",
        "\n",
        "# @markdown <FONT SIZE=5>**4. What NBM Region?**\n",
        "nbm_selection ='Alaska' # @param [\"Alaska\", \"CONUS\", \"Pacific\", \"Puerto Rico\"]\n",
        "nbm_region_dict = {'Alaska':'ak', 'CONUS':'co', 'Pacific':'hi', \"Puerto Rico\":\"pr\"}\n",
        "nbm_region = nbm_region_dict[nbm_selection]\n",
        "\n",
        "# Split element/interval\n",
        "interval_selection = int(element[-2:]) if \"qpf\" in element else False\n",
        "element = element[:3] if \"qpf\" in element else element\n",
        "#@markdown <FONT SIZE=5>**Which Site(s)?  (Enter a single four letter site identifier or a comma seperated list)**\n",
        "ob_sites = 'pajn' # @param {type:\"string\"}\n",
        "sites = [ob_sites]\n",
        "\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "# GLOBAL VARIABLES AND GENERAL CONFIG                                         #\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "# Multiprocess settings\n",
        "process_pool_size = 20 #cpu_count()*16\n",
        "print(f'Process Pool Size: {process_pool_size}')\n",
        "\n",
        "# Backend APIs\n",
        "metadata_api = \"https://api.synopticdata.com/v2/stations/metadata?\"\n",
        "qc_api = \"https://api.synopticdata.com/v2/stations/qcsegments?\"\n",
        "\n",
        "# Data Query APIs\n",
        "timeseries_api = \"https://api.synopticdata.com/v2/stations/timeseries?\"\n",
        "statistics_api = \"https://api.synopticlabs.org/v2/stations/statistics?\"\n",
        "precipitation_api = \"https://api.synopticdata.com/v2/stations/precipitation?\"\n",
        "\n",
        "\n",
        "# Assign API to element name\n",
        "synoptic_apis = {\n",
        "    'qpf':precipitation_api,\n",
        "    'maxt':timeseries_api,\n",
        "    'mint':timeseries_api,\n",
        "    'wind':timeseries_api,\n",
        "    'windgust':timeseries_api,\n",
        "    'temp':timeseries_api,\n",
        "    'rh': timeseries_api,\n",
        "    'td': timeseries_api}\n",
        "\n",
        "# Assign synoptic variable to element name\n",
        "synoptic_vars = {\n",
        "    'qpf':None,\n",
        "    'maxt':'air_temp',\n",
        "    'mint':'air_temp',\n",
        "    'wind': 'wind_speed',\n",
        "    'windgust': 'wind_gust',\n",
        "    'rh':'relative_humidity',\n",
        "    'td':'dew_point_temperature'\n",
        "}\n",
        "\n",
        "synoptic_vars_out = {\n",
        "    'qpf':'OBSERVATIONS.precipitation',\n",
        "    'maxt':'STATISTICS.air_temp_set_1.maximum',\n",
        "    'mint':'STATISTICS.air_temp_set_1.minimum',}\n",
        "\n",
        "\n",
        "ob_hours = {\n",
        "    'qpf':[['0000', '0000'], ['1200', '1200']],\n",
        "    'maxt':[['1200', '0600']],\n",
        "    'mint':[['0000', '1800']]}\n",
        "\n",
        "# NBM Globals\n",
        "aws_bucket_nbm = 'noaa-nbm-grib2-pds'\n",
        "aws_bucket_urma = 'noaa-urma-pds'\n",
        "\n",
        "# Where to place the grib files (subdirs can be added in local) (not used)\n",
        "output_dir = '/nas/atpg/data/nbm_verification/timeseries/'\n",
        "\n",
        "\n",
        "# Which grib variables do each element correlate with\n",
        "nbm_vars = {'qpf':'APCP',\n",
        "                  'maxt':'TMP',\n",
        "                  'mint':'TMP',\n",
        "                  'wind': 'WIND',\n",
        "                  'windgust': 'GUST',\n",
        "                  'rh': 'RH',\n",
        "                  'td': 'DPT'}\n",
        "\n",
        "# Which grib levels do each element correlate with\n",
        "nbm_levs = {'qpf':'surface',\n",
        "               'maxt':'2 m above ground',\n",
        "               'mint':'2 m above ground',\n",
        "               'wind': '2 m above ground',\n",
        "               'windgust': '2 m above ground',\n",
        "               'rh': '2 m above ground',\n",
        "               'td': '2 m above ground'}\n",
        "\n",
        "# Convert user input to datetime objects\n",
        "start_date, end_date = [datetime.strptime(date+' 0000', '%Y-%m-%d %H%M')\n",
        "    for date in [start_date, end_date]]\n",
        "\n",
        "# Bracket start date by 4.1 implementation\n",
        "if start_date < datetime(2023, 1, 18, 0, 0, 0):\n",
        "    start_date = datetime(2023, 1, 18, 0, 0, 0)\n",
        "\n",
        "\n",
        "# Build synoptic arg dict\n",
        "synoptic_api_args = {\n",
        "\n",
        "    'api':synoptic_apis[element],\n",
        "    'element':element,\n",
        "    'interval':interval_selection if element == 'qpf' else False,\n",
        "    'stid':sites,\n",
        "\n",
        "    'vars_query':None if element == 'qpf'\n",
        "        else f'{synoptic_vars[element]}',\n",
        "    'days_offset':1 if element != 'mint' else 0}\n",
        "\n",
        "# Build nbm/urma arg dict\n",
        "nbm_request_args = {\n",
        "    'interval':interval_selection if element == 'qpf' else False,\n",
        "    'nbm_area':nbm_region,\n",
        "    'element':element,\n",
        "    'var':nbm_vars[element],\n",
        "    'level':nbm_levs[element]}\n",
        "\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "# FUNCTIONS AND METHODS (GENERAL)                                             #\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "def mkdir_p(check_dir):\n",
        "    from pathlib import Path\n",
        "    check_dir = output_dir + check_dir\n",
        "    Path(check_dir).mkdir(parents=True, exist_ok=True)\n",
        "    return check_dir\n",
        "\n",
        "  # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "# FUNCTIONS AND METHODS (SYNOPTIC API)                                        #\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "def fetch_obs_from_API(start, end, utime, city, var, api, output_type='csv'):\n",
        "\n",
        "    valid = True\n",
        "\n",
        "    trtime = f'{utime:02d}'\n",
        "    trstart = start.strftime('%Y%m%d')+trtime+'00'\n",
        "    trend = end.strftime('%Y%m%d')+trtime+'00'\n",
        "\n",
        "\n",
        "    element_label = var if var != 'qpf' else \\\n",
        "    'qpe' + f'{interval_selection:02d}'\n",
        "\n",
        "    output_file = mkdir_p(f'obs_{output_type}/') +\\\n",
        "    f'obs.{element_label}.'+\\\n",
        "    f'.{start}.{end}.{output_type}'\n",
        "\n",
        "    if os.path.isfile(output_file):\n",
        "        print(f'File {output_file} already exists.')\n",
        "        return output_file\n",
        "    else:\n",
        "      json_file = mkdir_p('obs_json/')+\\\n",
        "      f'obs.{element_label}.' +\\\n",
        "      f'.{start}.{end}.json'\n",
        "\n",
        "      api_query_args = {\n",
        "          'api_token': f'&token={user_token}',\n",
        "          'stid': f'&stid={city}',\n",
        "          'start': f'&start={trstart}',\n",
        "          'end': f'&end={trend}',\n",
        "          'vars': f'&vars={synoptic_vars[var]}',\n",
        "          'format': f'&format=json',\n",
        "          'units': '&units=english'\n",
        "      }\n",
        "      api_query = api + ''.join(\n",
        "                [api_query_args[k] for k in api_query_args.keys()])\n",
        "\n",
        "      print(f'Polling API for: {api_query}')\n",
        "\n",
        "      status_code, response_count = None, 0\n",
        "      while (status_code != 200) & (response_count <= 10):\n",
        "          print(f'HTTP:{status_code}, #:{response_count}')\n",
        "\n",
        "          # Don't sleep first try, sleep increasing amount for each retry\n",
        "          time.sleep(2*response_count)\n",
        "\n",
        "          response = requests.get(api_query)\n",
        "          # response.raise_for_status()\n",
        "\n",
        "          status_code = response.status_code\n",
        "          response_count += 1\n",
        "\n",
        "      try:\n",
        "          response_dataframe = pd.json_normalize(\n",
        "              response.json()['STATION'])\n",
        "      except:\n",
        "          valid = False\n",
        "      else:\n",
        "          with open(json_file, 'wb+') as wfp:\n",
        "              wfp.write(response.content)\n",
        "\n",
        "    if valid:\n",
        "        # Check ACTIVE flag (Can disable in config above if desired)\n",
        "        response_dataframe = response_dataframe[\n",
        "            response_dataframe['STATUS'] == \"ACTIVE\"]\n",
        "\n",
        "        # Un-nest the QPF totals\n",
        "        if var == 'qpf':\n",
        "            response_dataframe['TOTAL'] = [i[0]['total']\n",
        "                for i in response_dataframe['OBSERVATIONS.precipitation']]\n",
        "\n",
        "        if output_type == 'pickle':\n",
        "        # Save out df as pickle\n",
        "            response_dataframe.to_pickle(output_file)\n",
        "\n",
        "        elif output_type == 'csv':\n",
        "        # Save out df as csv\n",
        "            response_dataframe.to_csv(output_file)\n",
        "\n",
        "        return None\n",
        "\n",
        "    return\n",
        "\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "# FUNCTIONS AND METHODS (NBM)                                                 #\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "def ll_to_index(loclat, loclon, datalats, datalons):\n",
        "    # index, loclat, loclon = loclatlon\n",
        "    abslat = np.abs(datalats-loclat)\n",
        "    abslon = np.abs(datalons-loclon)\n",
        "    c = np.maximum(abslon, abslat)\n",
        "    latlon_idx_flat = np.argmin(c)\n",
        "    latlon_idx = np.unravel_index(latlon_idx_flat, datalons.shape)\n",
        "    return latlon_idx\n",
        "\n",
        "def generate_hourly_intervals(start_time, end_time):\n",
        "    # Calculate the total number of hours between the start and end times\n",
        "    total_hours = int((end_time - start_time).total_seconds() // 3600)\n",
        "\n",
        "    # Generate the list of formatted strings\n",
        "    intervals = [f\"F{str(i+1).zfill(3)}\" for i in range(total_hours)]\n",
        "\n",
        "    return intervals\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "# INPUT-BASED GLOBAL VARIABLES AND CONFIG                                     #\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  for site in sites:\n",
        "    fetch_obs_from_API(start_date, end_date, utctime, site, element, timeseries_api)\n",
        "\n",
        "\n",
        "print(generate_hourly_intervals(start_date, end_date))\n",
        "\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "# DATA ACQUISITION                                                            #\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdXbkeRRU6Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JLdCf63WUlLl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n[Clang 13.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d9efab89797b4f7e4129f7fe7c375038c6a3f1b6c83da7efdea02c4da588d5be"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}